# Toxic Comments Classification
In this project, we tried to build a multi-headed model thatâ€™s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate in comments

Modules and packages used:  
matplotlib <br />
numpy <br />sklearn<br />Pandas<br />seaborn<br />xgboost
